{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KGP talkie\n",
    "#https://www.youtube.com/watch?v=2arr7TeiW-A&list=PLc2rvfiptPSTvPFbNlT_TGRupzKKhJSIv&index=7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* KNN is supervised machine learning algorithm that can be used to solve both classification and regression problems.\n",
    "* Classification is supervised learning in which the response variable is ' categorical ' \n",
    "* Regression is supervised learning in which response is ordered and continuous \n",
    "* Each value we are predicting is the response (also known as: target, outcome, label, dependent variable)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Requirements for working with data in scikit-learn  \n",
    "* 1.Features and response are separate objects.  \n",
    "\n",
    "* 2.Features and response should be numeric ( this is the reason why our response wine.target stored as 0's,1's,2's  instead of the strings 'class_1', 'class_2', 'class_3 ' ) ,in scikit learn the response varible is always numeric regardless of whether its a regression problem or classification problem.\n",
    "\n",
    "* 3.Features and response should be NumPy arrays( Numpy is a library for scientific computing that impliments homogeneous and multidimensional array known as an ndarray that has been optimised for fast computation, it turns out both wine.data,wine.target are alredy stored as ndarrays.\n",
    "\n",
    "* 4.Features and response should have specific shapes.(specifically the feature objects should have 2 dimensions ,the response objects is expected to have a single dimension and that dimension should have the same magnitude as the 1st dimension of the feature objects Or there should be one response corresponding to each observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Building in Python and Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the wine dataset, which is a very famous classification problem.\n",
    "# This dataset is the result of a chemical analysis of wines grown in the same region in italy using three different cultivars.\n",
    "# The analysis determined the quantitites of the constituents found in each of the three types of wines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset has 13 features, it has three types of cultiver classes 'class_0','class_1','class_2' \n",
    "# Here u can build a model to classify the type of cultiver.\n",
    "# This wine dataset available in scikit library or v can download it from uci machine learning repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = wine.data\n",
    "y = wine.target\n",
    "df = pd.DataFrame(X,columns = wine.feature_names) \n",
    "df['target'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((178, 13), (178,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset to understand model performance \n",
    "# split the dataset by using function train_test_split(). U need to pass 3 parameters (features, target,  test_set size)\n",
    "# additionaly,u can use (random_state) to select records randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating model for K = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we'll test for different values of K and finally decides which number of K is best suited for our classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6851851851851852\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train,y_train)\n",
    "y_predict = knn.predict(X_test)\n",
    "print('Accuracy: ',metrics.accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating model for K = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train,y_train)\n",
    "y_predict = knn.predict(X_test)\n",
    "print('Accuracy: ',metrics.accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating model for K = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7407407407407407\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "knn.fit(X_train,y_train)\n",
    "y_predict = knn.predict(X_test)\n",
    "print('Accuracy: ',metrics.accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we've increased the no.of neighbors in the model and accuracy got increased.But,this is not necesary for each and every case that an increase in many neighbors increases the accuracy.\n",
    "\n",
    "* #### Pros:\n",
    "\n",
    "* The training phase of KNN classification is much faster as compared to other classification algorithms. There is no need to train a model for generalization.That's why KNN is know as the simple and instance based algorithm. KNN can be useful in case of non linear data.It can be used with the regression problem. Output value for the object is computed by the average of k closest neighbors value. \n",
    "\n",
    "* #### Cons: \n",
    "\n",
    "* The testing phase of KNN is slower and costlier in terms of time and memory. It requires large memory for storing the entire training dataset for prediction. KNN requires scaling of data because KNN uses Eucledian distance between two points to find nearest neighbors. Eucledian distance is sensitive to magnitudes. The features with high magnitudes will weigth more than the features with low magnitudes. KNN also not suitable for large dimensional data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From Cons we've seen that knn requires scalling\n",
    "X\n",
    "# here 'x' is not a scalled version of data\n",
    "# So we need to standardise or normalise this data(x) to get better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this KNN works on the distance based matrix, suppose that if class-A have some values into scale A and scale A < 1\n",
    "# class-B have scale B and this scale B values r in 100,1000 then if calculate the distance between class-A and class-B we get \n",
    "# class weight tends to b skewed, so we need this classes or features to spaced into same dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to improve KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Standerdization in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.51861254, -0.5622498 ,  0.23205254, ...,  0.36217728,\n",
       "         1.84791957,  1.01300893],\n",
       "       [ 0.24628963, -0.49941338, -0.82799632, ...,  0.40605066,\n",
       "         1.1134493 ,  0.96524152],\n",
       "       [ 0.19687903,  0.02123125,  1.10933436, ...,  0.31830389,\n",
       "         0.78858745,  1.39514818],\n",
       "       ...,\n",
       "       [ 0.33275817,  1.74474449, -0.38935541, ..., -1.61212515,\n",
       "        -1.48544548,  0.28057537],\n",
       "       [ 0.20923168,  0.22769377,  0.01273209, ..., -1.56825176,\n",
       "        -1.40069891,  0.29649784],\n",
       "       [ 1.39508604,  1.58316512,  1.36520822, ..., -1.52437837,\n",
       "        -1.42894777, -0.59516041]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, if we compare X before standerdization and after standerdization(x_scaled) all the 13 features in the dataset has same\n",
    "# scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "# Now accuarcy should increase\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.3, random_state = 0, stratify = y)1\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "knn.fit(X_train,y_train)\n",
    "y_predict = knn.predict(X_test)\n",
    "print('Accuracy: ',metrics.accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After standerdization we could see that for K=7 our KNN accuracy has increased from 74% to 96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets do the parameter tuning with a Cross Validation and try to find out the best fit(i.e.,best number of nearest neighbors\n",
    "#  to this algorithm) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning with  Cross Validation\n",
    "\n",
    "   * In this section, we'll explore a method that can b used to tune the hyperparameter K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation can be used to estimate the test error associated with a learning method in order to evaluate its  performance, or to select  the appropriate level of flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = list(range(1,50,2))\n",
    "cv_scores = []\n",
    "\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn,X_scaled, y, cv=10, scoring = 'accuracy')\n",
    "    cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9439735982112143,\n",
       " 0.954499914000688,\n",
       " 0.9666322669418644,\n",
       " 0.9663398692810456,\n",
       " 0.97218782249742,\n",
       " 0.9718954248366012,\n",
       " 0.9666322669418644,\n",
       " 0.9666322669418644,\n",
       " 0.9725146198830409,\n",
       " 0.9725146198830409,\n",
       " 0.9725146198830409,\n",
       " 0.9833333333333334,\n",
       " 0.9718954248366012,\n",
       " 0.9660130718954247,\n",
       " 0.9660130718954247,\n",
       " 0.9660130718954247,\n",
       " 0.9718954248366012,\n",
       " 0.9718954248366012,\n",
       " 0.9718954248366012,\n",
       " 0.9663398692810456,\n",
       " 0.9610767113863089,\n",
       " 0.9610767113863089,\n",
       " 0.9551943584451325,\n",
       " 0.9551943584451325,\n",
       " 0.9551943584451325]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05602640178878571,\n",
       " 0.04550008599931199,\n",
       " 0.03336773305813556,\n",
       " 0.03366013071895435,\n",
       " 0.027812177502580027,\n",
       " 0.028104575163398815,\n",
       " 0.03336773305813556,\n",
       " 0.03336773305813556,\n",
       " 0.027485380116959113,\n",
       " 0.027485380116959113,\n",
       " 0.027485380116959113,\n",
       " 0.016666666666666607,\n",
       " 0.028104575163398815,\n",
       " 0.033986928104575265,\n",
       " 0.033986928104575265,\n",
       " 0.033986928104575265,\n",
       " 0.028104575163398815,\n",
       " 0.028104575163398815,\n",
       " 0.028104575163398815,\n",
       " 0.03366013071895435,\n",
       " 0.0389232886136911,\n",
       " 0.0389232886136911,\n",
       " 0.04480564155486755,\n",
       " 0.04480564155486755,\n",
       " 0.04480564155486755]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = [1 - x for x in cv_scores ]   # Mean Square Error\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Optimal number of k is:  23\n"
     ]
    }
   ],
   "source": [
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "print(\"The Optimal number of k is: \",optimal_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x243a3984dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(neighbors,MSE)\n",
    "plt.xlabel('Number of k')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From plot we see that 23 is showing the minimum error, so K=23 is the best result for our classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "# Let's check the accuracy at K=23\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.3, random_state = 0, stratify = y)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 23)\n",
    "knn.fit(X_train,y_train)\n",
    "y_predict = knn.predict(X_test)\n",
    "print('Accuracy: ',metrics.accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN implimenting on iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset consisits of 50 samples of 3 different species of iris(150 samples total)\n",
    "# Measurements: sepal length, sepal width, petal length, petal width\n",
    "\n",
    "# Framed as a supervised learning problem: Predict the species of an iris using the measurements\n",
    "# Famous dataset fro machine learning because prediction is easy\n",
    "# Learn more about the iris dataset: UCI Machine Learning Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the iris dataset into scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at iris.target u might be wondering how that this is a classification probelm and not a regression problem ?\n",
    "# Since all u can see is numbers 0,1,2 the answer is u cannot tell the difference, as a ML practitioner u have to understand how\n",
    "# your data is encoded and decide whether ur response variable is suited for regression and classification.\n",
    "\n",
    "# In this case(iris.data) we know that the numbrs 0,1,2 represent on order categories and thus v know to use classifiaction \n",
    "# techniques and not regression techniques inorder to solve this problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.read_csv('iris.csv')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = iris.iloc[:,0:4]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    setosa\n",
       "1    setosa\n",
       "2    setosa\n",
       "3    setosa\n",
       "4    setosa\n",
       "Name: Species, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = iris.iloc[:,-1]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.24744871391589"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by thumb rule we took n_neighbors(by sqrt(no of observations)) it is not applicable every time.\n",
    "# as the response or target variable has 3 diffrent classes v could go for n_neighbors = 3 but for now we go by thumb rule\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=12, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'virginica', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'versicolor',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'versicolor', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         setosa\n",
       "1         setosa\n",
       "2         setosa\n",
       "3         setosa\n",
       "4         setosa\n",
       "5         setosa\n",
       "6         setosa\n",
       "7         setosa\n",
       "8         setosa\n",
       "9         setosa\n",
       "10        setosa\n",
       "11        setosa\n",
       "12        setosa\n",
       "13        setosa\n",
       "14        setosa\n",
       "15        setosa\n",
       "16        setosa\n",
       "17        setosa\n",
       "18        setosa\n",
       "19        setosa\n",
       "20        setosa\n",
       "21        setosa\n",
       "22        setosa\n",
       "23        setosa\n",
       "24        setosa\n",
       "25        setosa\n",
       "26        setosa\n",
       "27        setosa\n",
       "28        setosa\n",
       "29        setosa\n",
       "         ...    \n",
       "120    virginica\n",
       "121    virginica\n",
       "122    virginica\n",
       "123    virginica\n",
       "124    virginica\n",
       "125    virginica\n",
       "126    virginica\n",
       "127    virginica\n",
       "128    virginica\n",
       "129    virginica\n",
       "130    virginica\n",
       "131    virginica\n",
       "132    virginica\n",
       "133    virginica\n",
       "134    virginica\n",
       "135    virginica\n",
       "136    virginica\n",
       "137    virginica\n",
       "138    virginica\n",
       "139    virginica\n",
       "140    virginica\n",
       "141    virginica\n",
       "142    virginica\n",
       "143    virginica\n",
       "144    virginica\n",
       "145    virginica\n",
       "146    virginica\n",
       "147    virginica\n",
       "148    virginica\n",
       "149    virginica\n",
       "Name: Species, Length: 150, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing predicted values(y_pred) with actual values(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How to convert series into array ?  Ans = y.values   check type(y.values)\n",
    "\n",
    "y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1\n",
       "0        setosa     setosa\n",
       "1        setosa     setosa\n",
       "2        setosa     setosa\n",
       "3        setosa     setosa\n",
       "4        setosa     setosa\n",
       "5        setosa     setosa\n",
       "6        setosa     setosa\n",
       "7        setosa     setosa\n",
       "8        setosa     setosa\n",
       "9        setosa     setosa\n",
       "10       setosa     setosa\n",
       "11       setosa     setosa\n",
       "12       setosa     setosa\n",
       "13       setosa     setosa\n",
       "14       setosa     setosa\n",
       "15       setosa     setosa\n",
       "16       setosa     setosa\n",
       "17       setosa     setosa\n",
       "18       setosa     setosa\n",
       "19       setosa     setosa\n",
       "20       setosa     setosa\n",
       "21       setosa     setosa\n",
       "22       setosa     setosa\n",
       "23       setosa     setosa\n",
       "24       setosa     setosa\n",
       "25       setosa     setosa\n",
       "26       setosa     setosa\n",
       "27       setosa     setosa\n",
       "28       setosa     setosa\n",
       "29       setosa     setosa\n",
       "..          ...        ...\n",
       "120   virginica  virginica\n",
       "121   virginica  virginica\n",
       "122   virginica  virginica\n",
       "123   virginica  virginica\n",
       "124   virginica  virginica\n",
       "125   virginica  virginica\n",
       "126   virginica  virginica\n",
       "127   virginica  virginica\n",
       "128   virginica  virginica\n",
       "129   virginica  virginica\n",
       "130   virginica  virginica\n",
       "131   virginica  virginica\n",
       "132   virginica  virginica\n",
       "133   virginica  virginica\n",
       "134   virginica  virginica\n",
       "135   virginica  virginica\n",
       "136   virginica  virginica\n",
       "137   virginica  virginica\n",
       "138  versicolor  virginica\n",
       "139   virginica  virginica\n",
       "140   virginica  virginica\n",
       "141   virginica  virginica\n",
       "142   virginica  virginica\n",
       "143   virginica  virginica\n",
       "144   virginica  virginica\n",
       "145   virginica  virginica\n",
       "146   virginica  virginica\n",
       "147   virginica  virginica\n",
       "148   virginica  virginica\n",
       "149   virginica  virginica\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining this predicted and actual values into dataframe\n",
    "\n",
    "a = pd.DataFrame(data = [y_pred,y.values])\n",
    "a.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In real world when using ML algorithm v split the dataset into training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=12, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'versicolor', 'setosa', 'virginica',\n",
       "       'versicolor', 'virginica', 'setosa', 'setosa', 'virginica',\n",
       "       'versicolor', 'setosa', 'virginica', 'versicolor', 'versicolor',\n",
       "       'setosa', 'versicolor', 'versicolor', 'setosa', 'setosa',\n",
       "       'versicolor', 'versicolor', 'virginica', 'setosa', 'virginica',\n",
       "       'versicolor', 'setosa', 'setosa', 'versicolor', 'virginica',\n",
       "       'versicolor', 'virginica', 'versicolor', 'virginica', 'virginica',\n",
       "       'setosa', 'versicolor', 'setosa', 'versicolor', 'virginica',\n",
       "       'virginica', 'setosa', 'virginica', 'virginica', 'versicolor'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = knn.predict(X_test)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'versicolor', 'setosa', 'virginica',\n",
       "       'versicolor', 'virginica', 'setosa', 'setosa', 'virginica',\n",
       "       'versicolor', 'setosa', 'virginica', 'versicolor', 'versicolor',\n",
       "       'setosa', 'versicolor', 'versicolor', 'setosa', 'setosa',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'setosa', 'virginica',\n",
       "       'versicolor', 'setosa', 'setosa', 'versicolor', 'virginica',\n",
       "       'versicolor', 'virginica', 'versicolor', 'virginica', 'virginica',\n",
       "       'setosa', 'versicolor', 'setosa', 'versicolor', 'virginica',\n",
       "       'virginica', 'setosa', 'virginica', 'virginica', 'versicolor'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1\n",
       "0       setosa      setosa\n",
       "1   versicolor  versicolor\n",
       "2   versicolor  versicolor\n",
       "3       setosa      setosa\n",
       "4    virginica   virginica\n",
       "5   versicolor  versicolor\n",
       "6    virginica   virginica\n",
       "7       setosa      setosa\n",
       "8       setosa      setosa\n",
       "9    virginica   virginica\n",
       "10  versicolor  versicolor\n",
       "11      setosa      setosa\n",
       "12   virginica   virginica\n",
       "13  versicolor  versicolor\n",
       "14  versicolor  versicolor\n",
       "15      setosa      setosa\n",
       "16  versicolor  versicolor\n",
       "17  versicolor  versicolor\n",
       "18      setosa      setosa\n",
       "19      setosa      setosa\n",
       "20  versicolor  versicolor\n",
       "21  versicolor  versicolor\n",
       "22   virginica  versicolor\n",
       "23      setosa      setosa\n",
       "24   virginica   virginica\n",
       "25  versicolor  versicolor\n",
       "26      setosa      setosa\n",
       "27      setosa      setosa\n",
       "28  versicolor  versicolor\n",
       "29   virginica   virginica\n",
       "30  versicolor  versicolor\n",
       "31   virginica   virginica\n",
       "32  versicolor  versicolor\n",
       "33   virginica   virginica\n",
       "34   virginica   virginica\n",
       "35      setosa      setosa\n",
       "36  versicolor  versicolor\n",
       "37      setosa      setosa\n",
       "38  versicolor  versicolor\n",
       "39   virginica   virginica\n",
       "40   virginica   virginica\n",
       "41      setosa      setosa\n",
       "42   virginica   virginica\n",
       "43   virginica   virginica\n",
       "44  versicolor  versicolor"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_output = pd.DataFrame(data = [y_test_pred,y_test.values])\n",
    "prediction_output.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
